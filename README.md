<!-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
     MedGemma Clinical Workflow Engine â€” README
     â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• -->

<div align="center">

# ğŸ¥ MedGemma Clinical Workflow Engine

**A multi-agent medical assistant powered by MedGemma, MedASR & LiteLLM**

13 clinical workflows Â· 12 pre-built scenarios Â· voice dictation Â· image / PDF / CSV upload

[![Python 3.11+](https://img.shields.io/badge/Python-3.11%2B-blue?logo=python&logoColor=white)](#prerequisites)
[![Flask](https://img.shields.io/badge/Flask-3.0-lightgrey?logo=flask)](#quick-start-step-by-step)
[![License: Research](https://img.shields.io/badge/License-Research%20%2F%20Educational-green)](#license)

</div>

---

<!-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
     ARCHITECTURE OVERVIEW â€” SVG diagram
     Shows the high-level data-flow: User â†” Flask â†” Agents / Workflows â†” Models
     The SVG is stored at the repo root alongside its PNG fallback.
     â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• -->

<div align="center">

### Architecture Overview

<img src="architecture_overview.svg" alt="Architecture Overview" width="800"/>

<br/>
<sub><i>Data-flow: User â†” Flask UI â†” Multi-Agent Orchestrator / Workflow Engine â†” MedGemma Â· MedASR Â· Groq LLM</i></sub>

</div>

---

<!-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
     DEMO VIDEO â€” MP4 walkthrough
     Full walkthrough showing scenarios, free chat, and workflow execution.
     The video file lives in video/medgemmachallenge_demo.mp4.
     GitHub renders <video> tags in README; for other hosts use the download link.
     â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• -->

<div align="center">

### ğŸ¬ Demo Video

<video src="video/medgemmachallenge_demo.mp4" controls width="800">
  Your browser does not support the video tag.
</video>

<br/>

> **Can't play the video above?** Download it directly:
> [`video/medgemmachallenge_demo.mp4`](video/medgemmachallenge_demo.mp4)

</div>

---

<!-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
     WORKFLOW CARD THUMBNAIL â€” SVG card grid preview
     Visual preview of the 13 workflow cards as shown on the /workflows page.
     â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• -->

<div align="center">

### Workflow Cards

<img src="card_thumbnail.svg" alt="Workflow Cards Preview" width="700"/>

</div>

---

## Table of Contents

- [Features](#features)
- [Prerequisites](#prerequisites)
- [Quick Start (Step by Step)](#quick-start-step-by-step)
  - [1 â€” Clone the Repository](#1--clone-the-repository)
  - [2 â€” Create a Python Environment](#2--create-a-python-environment)
  - [3 â€” Install Dependencies](#3--install-dependencies)
  - [4 â€” Install ffmpeg (for voice dictation)](#4--install-ffmpeg-for-voice-dictation)
  - [5 â€” Get API Keys](#5--get-api-keys)
  - [6 â€” Configure Environment Variables](#6--configure-environment-variables)
  - [7 â€” Download Model Weights (Optional)](#7--download-model-weights-optional)
  - [8 â€” Run the Application](#8--run-the-application)
  - [9 â€” Run Tests (Optional)](#9--run-tests-optional)
- [Usage Guide](#usage-guide)
- [Clinical Workflows](#clinical-workflows)
- [Project Structure](#project-structure)
- [API Reference](#api-reference)
- [Architecture Deep Dive](#architecture-deep-dive)
- [Environment Variables Reference](#environment-variables-reference)
- [Troubleshooting](#troubleshooting)
- [License](#license)

---

## Features

| Page | Route | Description |
|------|-------|-------------|
| **Scenarios** | `/` | 12 pre-built clinical scenarios (headache triage, chest X-ray, emergency, etc.) |
| **Free Chat** | `/chat` | Open-ended multi-turn medical conversation with image/PDF upload |
| **Workflows** | `/workflows` | 3Ã—N grid of 13 protocol-adherent clinical workflows |

### Input Methods

| Method | Details |
|--------|---------|
| **Text** | Free-text clinical notes in the chat input |
| **Image** | Drag-and-drop or file picker (PNG, JPG, TIFF, WebP) â€” analyzed by MedGemma |
| **PDF** | Drag-and-drop; server extracts text via `pypdf` |
| **CSV** | Drag-and-drop or paste; supports flexible column names |
| **Voice** | Browser microphone â†’ MedASR (Conformer-CTC, 105M params, 16 kHz mono) |

### Models Used

<!-- â”€â”€â”€ This table describes the three AI models the system relies on â”€â”€â”€â”€â”€â”€
     MedGemma and MedASR run LOCALLY â€” patient data never leaves the host.
     The Groq LLM is a cloud API used for orchestration only.
     MedGemma requires a GPU with â‰¥8 GB VRAM for quantized (NF4) inference.
     â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ -->

| Model | Source | Size | Purpose | Runs On |
|-------|--------|------|---------|---------|
| **MedGemma 1.5 4B-IT** | `google/medgemma-1.5-4b-it` | ~4 GB | Vision-language medical analysis (triage, imaging, SOAP notes) | Local GPU (â‰¥8 GB VRAM) |
| **MedASR** | `google/medasr` | ~400 MB | Medical speech-to-text (Conformer-CTC, 5 000 h training) | CPU or GPU |
| **GPT-OSS 120B** (via Groq) | `groq/openai/gpt-oss-120b` | Cloud API | Agent orchestration, tool-call dispatch, data extraction | Groq Cloud |

---

## Prerequisites

Before starting, make sure you have:

- **Python 3.11+** â€” [Download](https://www.python.org/downloads/)
- **Git** â€” [Download](https://git-scm.com/downloads)
- **A Groq API key** (free) â€” [Get one here](https://console.groq.com/keys)
- **A HuggingFace account + access token** â€” [Sign up](https://huggingface.co/join) Â· [Generate token](https://huggingface.co/settings/tokens)
- **GPU with â‰¥8 GB VRAM** (recommended) â€” for MedGemma vision inference. CPU-only works for everything else.
- **ffmpeg** (optional) â€” required only for voice dictation with non-WAV audio formats

---

## Quick Start (Step by Step)

### 1 â€” Clone the Repository

```bash
git clone https://github.com/YouvenZ/MedFlowAssit.git
cd MedFlowAssit
```

### 2 â€” Create a Python Environment

<!-- â”€â”€â”€ Choose ONE of the methods below (conda OR venv) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
     conda is recommended because it simplifies installing CUDA/PyTorch.
     venv is perfectly fine if you don't have conda installed.
     â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ -->

**Option A â€” conda (recommended):**

```bash
conda create -n medgemma python=3.11 -y
conda activate medgemma
```

**Option B â€” venv:**

```bash
# Windows
python -m venv .venv
.venv\Scripts\activate

# macOS / Linux
python3 -m venv .venv
source .venv/bin/activate
```

### 3 â€” Install Dependencies

```bash
pip install -r requirements.txt
```

<!-- â”€â”€â”€ What requirements.txt installs â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
     Core:        flask, python-dotenv
     LLM:         litellm (routes calls to Groq / OpenAI / any provider)
     MedGemma:    transformers, torch, Pillow, bitsandbytes (NF4 quantization)
     MedASR:      numpy, pydub (WebM â†’ WAV audio conversion)
     PDF:         pypdf (text extraction from uploaded PDFs)
     Testing:     colorama, huggingface-hub
     See requirements.txt for the full annotated dependency list.
     â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ -->

> **Note (GPU users):** If you have an NVIDIA GPU with CUDA, install the GPU-enabled PyTorch **before** the above command:
> ```bash
> # Example for CUDA 12.1 â€” adjust for your CUDA version
> pip install torch torchvision --index-url https://download.pytorch.org/whl/cu121
> ```

### 4 â€” Install ffmpeg (for voice dictation)

<!-- â”€â”€â”€ ffmpeg is needed by pydub to convert browser WebM audio to 16 kHz WAV
     which MedASR requires as input. If you don't plan to use the microphone
     button, you can safely skip this step.
     â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ -->

> **Skip this step** if you don't need voice dictation.

```bash
# Windows (chocolatey)
choco install ffmpeg

# Windows (winget)
winget install ffmpeg

# macOS
brew install ffmpeg

# Ubuntu / Debian
sudo apt install ffmpeg
```

Verify installation:

```bash
ffmpeg -version
```

### 5 â€” Get API Keys

You need **two** keys/tokens:

#### a) Groq API Key (required)

<!-- â”€â”€â”€ The Groq key powers the cloud LLM used for agentic orchestration,
     tool-call dispatch, and patient-facing conversation.
     The free tier has generous rate limits for development and demo use.
     â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ -->

1. Go to [console.groq.com/keys](https://console.groq.com/keys)
2. Create a new API key
3. Copy it â€” it starts with `gsk_`

#### b) HuggingFace Token (required for MedGemma)

<!-- â”€â”€â”€ MedGemma is a "gated" model on HuggingFace, meaning you must accept
     the license agreement before the weights can be downloaded.
     The HF_TOKEN authenticates your download request.
     â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ -->

1. Create an account at [huggingface.co/join](https://huggingface.co/join)
2. Go to [huggingface.co/google/medgemma-1.5-4b-it](https://huggingface.co/google/medgemma-1.5-4b-it) and **accept the model license**
3. Generate a token at [huggingface.co/settings/tokens](https://huggingface.co/settings/tokens) (read access is sufficient)
4. Copy the token â€” it starts with `hf_`

### 6 â€” Configure Environment Variables

<!-- â”€â”€â”€ The .env file stores secrets locally and is loaded by python-dotenv
     at startup. NEVER commit your real .env file to git.
     The .env.example file is a safe, annotated template you can copy.
     â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ -->

Copy the example template and fill in your keys:

```bash
# Linux / macOS
cp .env.example .env

# Windows (Command Prompt)
copy .env.example .env

# Windows (PowerShell)
Copy-Item .env.example .env
```

Open `.env` in your editor and set the **required** values:

```env
# â”€â”€â”€ REQUIRED â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Groq API key â€” powers the cloud LLM for orchestration & extraction
GROQ_API_KEY=gsk_your_actual_key_here

# HuggingFace token â€” needed to download gated MedGemma model weights
HF_TOKEN=hf_your_actual_token_here

# â”€â”€â”€ OPTIONAL (defaults are fine for most users) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# MEDASR_MODEL=google/medasr       # Override MedASR model ID
# MEDASR_DEVICE=cpu                # Set to "cuda" for GPU-accelerated ASR
```

> **Full reference:** See [`.env.example`](.env.example) for the complete annotated template with explanations for every variable.

### 7 â€” Download Model Weights (Optional)

<!-- â”€â”€â”€ Pre-downloading is useful for offline / air-gapped environments
     or to avoid a long wait on your first API request.
     If you skip this, models download automatically on first use.
     Weights are cached in ~/.cache/huggingface/ and only download once.
     â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ -->

Pre-download models so the first request isn't slow:

```bash
python download_and_test.py --download-only
```

| Model | Download Size | Cache Location |
|-------|--------------|----------------|
| MedGemma 1.5 4B-IT | ~4 GB | `~/.cache/huggingface/` |
| MedASR | ~400 MB | `~/.cache/huggingface/` |

> **Skip this?** Models auto-download on first use. This step just avoids a wait during your first request.

### 8 â€” Run the Application

```bash
python app.py
```

Open your browser to **http://localhost:5000** and you should see the Scenarios page.

| Page | URL | What it does |
|------|-----|-------------|
| Scenarios | [localhost:5000/](http://localhost:5000/) | 12 pre-built clinical scenarios |
| Free Chat | [localhost:5000/chat](http://localhost:5000/chat) | Open medical chat with uploads |
| Workflows | [localhost:5000/workflows](http://localhost:5000/workflows) | 13-card clinical workflow grid |

**Alternative â€” CLI mode** (terminal-based, no browser needed):

```bash
python main.py                          # Interactive REPL (default)
python main.py demo                     # Run all 12 scenarios end-to-end
python main.py scenario 3               # Run a single scenario by number
python main.py --model groq/llama-3.3-70b-versatile interactive  # Custom model
```

### 9 â€” Run Tests (Optional)

<!-- â”€â”€â”€ The test script validates the LLM connection, all API endpoints,
     and all 13 workflow executions. The Flask app must be running on
     localhost:5000 for API tests â€” start it in a separate terminal first.
     â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ -->

Start the app first (`python app.py`), then in a **separate terminal**:

```bash
# Full test suite: models + LLM + endpoints + workflows
python download_and_test.py --test-all

# Individual test modes:
python download_and_test.py --download-only      # Pre-download HF models only
python download_and_test.py --test-llm           # Test Groq LLM API connection
python download_and_test.py --test-api           # Test all Flask API endpoints
python download_and_test.py --test-workflows     # Test all 13 workflow executions
```

---

## Usage Guide

### Scenario Mode (recommended for first-time users)

1. Open [localhost:5000](http://localhost:5000/)
2. Click any scenario card (e.g. **"Headache + triage"**)
3. The system auto-sends pre-built patient messages
4. Watch the multi-agent pipeline: intake â†’ triage â†’ clinical note â†’ booking

### Free Chat Mode

1. Open [localhost:5000/chat](http://localhost:5000/chat)
2. Type symptoms, drag-and-drop images, upload PDFs, or click the ğŸ¤ microphone button
3. The agent collects information, triages via MedGemma, and guides through scheduling

### Workflow Mode

1. Open [localhost:5000/workflows](http://localhost:5000/workflows)
2. Click any workflow card (e.g. **"StrokeRisk+"**)
3. Enter clinical text, upload a PDF/image, or paste CSV data
4. Click **Run** â€” the result appears as a structured clinical report with scores and metrics

---

## Clinical Workflows

### Text / PDF / Image â€” Medicine Rules & Scoring

| # | Workflow | Specialty | Protocol | Input | Description |
|---|----------|-----------|----------|-------|-------------|
| 1 | **RetinaCounter** | Ophthalmology | ICDR Scale | Image | Diabetic retinopathy grading from fundus images |
| 2 | **StrokeRisk+** | Cardiology | CHAâ‚‚DSâ‚‚-VASc | Text, PDF | 7-factor stroke risk calculator |
| 3 | **Med-Rec Guard** | Geriatrics | AGS Beers 2023 | Image, Text, PDF | Medication reconciliation against Beers Criteria |
| 4 | **TriageFlag** | Radiology | ACR Actionable | Text, PDF | Critical finding triage â€” 3-level urgency |
| 5 | **GrowthPlotter** | Pediatrics | CDC/WHO Charts | Text | Growth percentile calculator (BMI, weight, height) |
| 6 | **ConsultScribe** | General Practice | SOAP + ICD-10 | Text | SOAP note generator with ICD-10 coding |
| 7 | **qSOFA Calc** | Emergency Medicine | qSOFA (Sepsis-3) | Text, PDF | Quick SOFA sepsis screening â€” 3 bedside criteria |
| 8 | **WellsPE** | Pulmonology | Wells Criteria | Text, PDF | Pulmonary embolism probability â€” 7-item rule |
| 9 | **MELD-Na Calc** | Hepatology | MELD-Na (UNOS 2016) | Text, PDF | Liver disease severity & transplant priority |
| 10 | **GCS Calc** | Neurology | Glasgow Coma Scale | Text, PDF | E+V+M neurological assessment with TBI grade |

### CSV-Based â€” Tabular Healthcare Data

| # | Workflow | Specialty | Protocol | Input | Description |
|---|----------|-----------|----------|-------|-------------|
| 11 | **LabFlagr** | Pathology / Lab | Reference Ranges | CSV | Flag abnormals, critical values, compute eGFR / anion gap |
| 12 | **RxInteract** | Pharmacy | Drug Interaction DB | CSV | Pairwise drug-drug interaction check (HIGH/MODERATE/LOW) |
| 13 | **VitalsTrend** | ICU / Nursing | NEWS2 (RCP) | CSV | Serial vitals â†’ NEWS2 scoring + deterioration trends |

<!-- â”€â”€â”€ All workflows follow a chain-based (NOT agentic) architecture.
     The LLM only extracts structured variables from free text; all clinical
     scoring is performed by deterministic Python logic using published formulae.
     This guarantees reproducibility â€” identical inputs always yield identical scores.
     CSV workflows (#11-13) use ZERO LLM calls and are purely algorithmic.
     â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ -->

**Architecture:** Every workflow follows a **chain-based** (non-agentic) pattern:

```
Input â†’ LLM Extraction / CSV Parse â†’ Deterministic Python Logic â†’ Structured JSON Output
```

---

## Project Structure

<!-- â”€â”€â”€ The project is organized into logical sections:
     Entry points, Agent system, AI models, Domain logic, Workflows, Frontend, Assets.
     Each file has a single responsibility.
     â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ -->

```
MedFlowAssit/
â”‚
â”œâ”€â”€ .env.example              # â† Environment variable template (copy to .env)
â”œâ”€â”€ .env                      # â† Your local secrets (git-ignored â€” never commit!)
â”œâ”€â”€ requirements.txt          # Python dependencies (annotated by category)
â”‚
â”‚   â”€â”€ Entry Points â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”œâ”€â”€ app.py                    # Flask web application â€” all routes & UI pages
â”œâ”€â”€ main.py                   # CLI entry point (interactive REPL / demo / scenario)
â”‚
â”‚   â”€â”€ Agent System â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”œâ”€â”€ base_agent.py             # Abstract BaseAgent â€” reusable tool-calling loop
â”œâ”€â”€ medical_agent.py          # MedicalAppointmentAgent â€” top-level facade
â”œâ”€â”€ orchestrator.py           # Multi-agent orchestrator (patient â†” doctor handoff)
â”œâ”€â”€ patient_agent.py          # PatientAgent â€” demographics, symptoms, image upload
â”œâ”€â”€ doctor_agent.py           # DoctorAgent â€” triage, SOAP notes, scheduling
â”œâ”€â”€ paperwork_agent.py        # PaperworkAgent â€” summaries, referrals, reminders
â”‚
â”‚   â”€â”€ AI Model Clients â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”œâ”€â”€ llm_config.py             # LiteLLM wrapper â€” llm_completion(), DEFAULT_MODEL
â”œâ”€â”€ medgemma_client.py        # MedGemma vision-language pipeline (4B-IT, NF4 quant)
â”œâ”€â”€ medasr.py                 # MedASR speech-to-text (Conformer-CTC, lazy singleton)
â”‚
â”‚   â”€â”€ Domain Logic â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”œâ”€â”€ specialty.py              # Specialty enum + 23 specialty system prompts
â”œâ”€â”€ db.py                     # SQLite DB (44 doctors, 22 specialties, time slots)
â”œâ”€â”€ pdf_extract.py            # PDF text extraction (pypdf / PyPDF2 / pdfplumber)
â”‚
â”‚   â”€â”€ Utilities â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”œâ”€â”€ download_and_test.py      # Model downloader + full endpoint/workflow test suite
â”‚
â”‚   â”€â”€ Workflow Engine (13 clinical workflows) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”œâ”€â”€ workflows/
â”‚   â”œâ”€â”€ __init__.py           # Workflow registry (get_all_cards, run_workflow)
â”‚   â”œâ”€â”€ base.py               # ClinicalWorkflow ABC, WorkflowResult, InputType
â”‚   â”œâ”€â”€ retina_counter.py     # ICDR diabetic retinopathy grading
â”‚   â”œâ”€â”€ stroke_risk.py        # CHAâ‚‚DSâ‚‚-VASc stroke risk calculator
â”‚   â”œâ”€â”€ medrec_guard.py       # AGS Beers Criteria medication reconciliation
â”‚   â”œâ”€â”€ triage_flag.py        # ACR critical finding triage
â”‚   â”œâ”€â”€ growth_plotter.py     # CDC/WHO growth percentile calculator
â”‚   â”œâ”€â”€ consult_scribe.py     # SOAP note + ICD-10 generator
â”‚   â”œâ”€â”€ qsofa_calc.py         # qSOFA sepsis screening (Sepsis-3)
â”‚   â”œâ”€â”€ wells_pe.py           # Wells criteria for pulmonary embolism
â”‚   â”œâ”€â”€ meld_calc.py          # MELD-Na liver disease score (UNOS 2016)
â”‚   â”œâ”€â”€ gcs_calc.py           # Glasgow Coma Scale (E+V+M)
â”‚   â”œâ”€â”€ lab_flagr.py          # CSV lab panel analyzer (100+ reference ranges)
â”‚   â”œâ”€â”€ rx_interact.py        # CSV drug interaction checker (40+ pairs)
â”‚   â””â”€â”€ vitals_trend.py       # CSV vitals trend + NEWS2 scoring
â”‚
â”‚   â”€â”€ Frontend â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”œâ”€â”€ templates/
â”‚   â”œâ”€â”€ index.html            # Scenarios page (/)
â”‚   â”œâ”€â”€ chat.html             # Free Chat page (/chat)
â”‚   â””â”€â”€ workflows.html        # Workflow Grid (/workflows)
â”œâ”€â”€ static/
â”‚   â””â”€â”€ style.css             # All CSS styles
â”‚
â”‚   â”€â”€ Assets & Media â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”œâ”€â”€ architecture_overview.svg # System architecture diagram (SVG)
â”œâ”€â”€ architecture_overview.png # Architecture diagram (PNG fallback)
â”œâ”€â”€ card_thumbnail.svg        # Workflow card grid preview (SVG)
â”œâ”€â”€ card_thumbnail.png        # Workflow card preview (PNG fallback)
â”œâ”€â”€ video/
â”‚   â””â”€â”€ medgemmachallenge_demo.mp4  # Full demo walkthrough video
â”‚
â”œâ”€â”€ uploads/                  # Temporary upload directory (auto-created at runtime)
â”œâ”€â”€ writeup.md                # Detailed project writeup / paper
â””â”€â”€ README.md                 # â† You are here
```

---

## API Reference

### Pages

| Method | Route | Description |
|--------|-------|-------------|
| `GET` | `/` | Scenarios page |
| `GET` | `/chat` | Free Chat page |
| `GET` | `/workflows` | Workflow Grid Interface |

### Agent / Chat Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| `POST` | `/api/chat` | Send a message to the medical agent |
| `POST` | `/api/reset` | Reset the agent session |
| `GET` | `/api/status` | Current agent state & phase |
| `POST` | `/api/scenario/<num>` | Start a pre-built scenario (1â€“12) |
| `POST` | `/api/paperwork` | Generate clinical documentation for current session |

### Workflow Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| `GET` | `/api/workflows` | List all 13 workflow cards (metadata) |
| `POST` | `/api/workflows/run` | Execute a workflow by `workflow_id` |

**Example â€” text workflow request:**

```json
{
  "workflow_id": "stroke_risk",
  "text": "72-year-old male with atrial fibrillation, hypertension, diabetesâ€¦"
}
```

**Example â€” CSV workflow request:**

```json
{
  "workflow_id": "lab_flagr",
  "csv_text": "test,value,unit\nHemoglobin,8.5,g/dL\nWBC,15.2,Ã—10Â³/ÂµL\nPotassium,6.1,mEq/L"
}
```

**Standard response schema (all workflows):**

```json
{
  "workflow_id": "stroke_risk",
  "status": "success",
  "data": {
    "summary": "CHAâ‚‚DSâ‚‚-VASc Score: 4/9. Estimated annual stroke risk: 4.8%.",
    "metrics": { "score": "4/9", "annual_stroke_risk": "4.8%" },
    "protocol_adherence": true,
    "raw_output": "â•â•â• CHAâ‚‚DSâ‚‚-VASc STROKE RISK REPORT â•â•â•\n..."
  },
  "artifacts": []
}
```

### Upload & Transcription Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| `POST` | `/api/upload/image` | Upload image â†’ base64 data-URI |
| `POST` | `/api/upload/pdf` | Upload PDF â†’ extracted text |
| `POST` | `/api/upload/csv` | Upload CSV â†’ raw text content |
| `POST` | `/api/transcribe` | Audio â†’ MedASR transcription (file or base64 JSON) |
| `GET` | `/api/medasr/status` | Check MedASR model availability |

---

## Architecture Deep Dive

### Multi-Agent System (Scenarios & Chat)

<!-- â”€â”€â”€ The Orchestrator uses keyword-scoring intent classification to route
     messages between PatientAgent (intake phase) and DoctorAgent (scheduling).
     Each agent extends BaseAgent, which implements a reusable tool-calling loop:
     the LLM receives tool schemas â†’ invokes functions â†’ receives results â†’
     iterates up to 12 rounds until producing a final text response.
     The handoff from PatientAgent to DoctorAgent is automatic: once the
     orchestrator detects that intake is complete, it transfers structured
     patient data (demographics, symptoms, triage result) to the DoctorAgent.
     â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ -->

```
User
 â”‚
 â–¼
Orchestrator â”€â”€â†’ PatientAgent  (intake: demographics, symptoms, image upload)
 â”‚                  â”‚
 â”‚                  â”œâ”€â”€â†’ MedGemma  (symptom triage, image analysis)
 â”‚                  â””â”€â”€â†’ MedASR   (voice dictation â†’ text)
 â”‚
 â”‚  â”€â”€â”€â”€ automatic handoff when intake is complete â”€â”€â”€â”€
 â”‚
 â”œâ”€â”€â”€â”€â”€â”€â†’ DoctorAgent   (clinical note via MedGemma, scheduling via SQLite DB)
 â”‚
 â””â”€â”€â”€â”€â”€â”€â†’ PaperworkAgent (appointment summaries, referral letters, reminders)
```

### Workflow Engine (deterministic chains)

<!-- â”€â”€â”€ Workflows are NOT agentic. They follow a strict 2-step chain:
     1. LLM extracts structured variables (or CSV is parsed directly)
     2. Deterministic Python logic applies published clinical formulae
     This ensures reproducibility â€” same input always gives same score.
     â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ -->

```
UI Card click â†’ POST /api/workflows/run
             â†’ WorkflowRegistry.run_workflow(id, data)
             â†’ ClinicalWorkflow.run()
                 â”œâ”€â”€ validate_input()       # Check required fields & input type
                 â”œâ”€â”€ execute()
                 â”‚     â”œâ”€â”€ Step 1: LLM extraction OR CSV parse
                 â”‚     â””â”€â”€ Step 2: Deterministic Python logic (published formulae)
                 â””â”€â”€ WorkflowResult         # Standard JSON output schema
```

### Database

<!-- â”€â”€â”€ SQLite is used for scheduling (doctors, time slots, appointments).
     The DB file (medical_appointments.db) auto-creates on first run
     with seed data: 44 doctors across 22 specialties, 14 days of time slots.
     If you encounter database issues, simply delete the .db file and restart.
     â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ -->

The SQLite database (`medical_appointments.db`) is **auto-created on first run** with:
- **44 doctors** across 22 medical specialties
- **14 days** of appointment time slots per doctor
- Full lifecycle: booking â†’ retrieval â†’ rescheduling â†’ cancellation

---

## Environment Variables Reference

<!-- â”€â”€â”€ Complete reference of every environment variable the app reads.
     Only GROQ_API_KEY is strictly required to start the app.
     HF_TOKEN is required specifically for downloading MedGemma weights.
     All other variables have sensible defaults.
     See .env.example for a copy-paste template with inline comments.
     â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ -->

| Variable | Required | Default | Description |
|----------|----------|---------|-------------|
| `GROQ_API_KEY` | **Yes** | â€” | Groq API key for the cloud LLM ([get one](https://console.groq.com/keys)) |
| `HF_TOKEN` | **Yes**\* | â€” | HuggingFace access token for gated model downloads ([get one](https://huggingface.co/settings/tokens)) |
| `MEDASR_MODEL` | No | `google/medasr` | HuggingFace model ID for MedASR speech-to-text |
| `MEDASR_DEVICE` | No | `cpu` | Torch device for MedASR inference (`cpu` or `cuda`) |
| `FLASK_SECRET_KEY` | No | hardcoded demo key | Flask session cookie signing key (change in production!) |
| `FLASK_DEBUG` | No | `0` | Set to `1` for Flask auto-reload during development |
| `TEST_BASE_URL` | No | `http://localhost:5000` | Base URL used by the test script |

\* `HF_TOKEN` is required only when using MedGemma vision features (gated model). Not needed for text-only or CSV workflows.

---

## Troubleshooting

<!-- â”€â”€â”€ Common issues encountered during setup and their solutions â”€â”€â”€â”€â”€â”€â”€â”€ -->

| Problem | Solution |
|---------|----------|
| `GROQ_API_KEY not set` error | Ensure `.env` exists in the project root and contains `GROQ_API_KEY=gsk_...` |
| `401 Unauthorized` from HuggingFace | Accept the MedGemma license at [the model page](https://huggingface.co/google/medgemma-1.5-4b-it) and verify `HF_TOKEN` in `.env` |
| `CUDA out of memory` | MedGemma needs â‰¥8 GB VRAM. Close other GPU apps, or set quantization to INT8/CPU |
| `ffmpeg not found` | Install ffmpeg ([Step 4](#4--install-ffmpeg-for-voice-dictation)) or skip voice dictation |
| `pydub.exceptions.CouldntDecodeError` | ffmpeg is missing from PATH â€” reinstall or add its bin directory to system PATH |
| MedASR download hangs | Check internet; model is ~400 MB. Pre-download with `python download_and_test.py --download-only` |
| `ModuleNotFoundError: bitsandbytes` | Run `pip install bitsandbytes`. Windows users: `pip install bitsandbytes-windows` |
| Database errors | Delete `medical_appointments.db` and restart â€” it auto-recreates with seed data |
| Workflows return `"status": "error"` | Check terminal logs for the full traceback. Common causes: missing input fields or malformed CSV |
| `torch not compiled with CUDA` | Install the CUDA-enabled PyTorch build matching your CUDA version ([pytorch.org](https://pytorch.org/get-started/locally/)) |

---

## License

This project is for **educational and research purposes**.

---

<div align="center">

**Source:** [github.com/YouvenZ/MedFlowAssit](https://github.com/YouvenZ/MedFlowAssit)

Built by **Dr. Rachid Zeghlache** & **Dr. Yassine Mamou**

</div>
