# ═══════════════════════════════════════════════════════════════════════════════
#  MedGemma Clinical Workflow Engine — Environment Configuration
# ═══════════════════════════════════════════════════════════════════════════════
#
#  Copy this file to `.env` in the project root and fill in your values:
#
#      cp .env.example .env        # Linux / macOS
#      copy .env.example .env      # Windows
#
#  The application loads variables from `.env` automatically via python-dotenv.
# ═══════════════════════════════════════════════════════════════════════════════


# ─────────────────────────────────────────────────────────────────────────────
#  SECTION 1 — LLM API KEY  (REQUIRED)
# ─────────────────────────────────────────────────────────────────────────────
#  A Groq API key is required for the cloud LLM (used for agent orchestration,
#  tool-call dispatch, data extraction, and patient-facing dialogue).
#
#  Get a free key at: https://console.groq.com/keys
#  The default model is `groq/openai/gpt-oss-120b` (see llm_config.py).
#
GROQ_API_KEY=gsk_your_groq_api_key_here


# ─────────────────────────────────────────────────────────────────────────────
#  SECTION 2 — HUGGING FACE ACCESS TOKEN  (REQUIRED for gated models)
# ─────────────────────────────────────────────────────────────────────────────
#  MedGemma (google/medgemma-1.5-4b-it) is a gated model on HuggingFace.
#  You must:
#    1. Create a HuggingFace account at https://huggingface.co/join
#    2. Accept the model license at https://huggingface.co/google/medgemma-1.5-4b-it
#    3. Generate an access token at https://huggingface.co/settings/tokens
#
#  This token is used by `transformers` to download gated model weights.
#
HF_TOKEN=hf_your_huggingface_token_here


# ─────────────────────────────────────────────────────────────────────────────
#  SECTION 3 — MedASR SPEECH-TO-TEXT  (OPTIONAL)
# ─────────────────────────────────────────────────────────────────────────────
#  MedASR is a Conformer-CTC model for medical dictation (~400 MB).
#  It loads lazily on first voice-dictation request.
#
#  MEDASR_MODEL  — HuggingFace model ID. Default: google/medasr
#  MEDASR_DEVICE — Torch device for inference. Default: cpu
#                  Set to "cuda" if you have a GPU and want faster transcription.
#
# MEDASR_MODEL=google/medasr
# MEDASR_DEVICE=cpu


# ─────────────────────────────────────────────────────────────────────────────
#  SECTION 4 — FLASK SETTINGS  (OPTIONAL)
# ─────────────────────────────────────────────────────────────────────────────
#  These settings control the Flask web server. Defaults are fine for local
#  development; override them for production deployments.
#
#  FLASK_SECRET_KEY — Session cookie signing key. Change in production!
#  FLASK_DEBUG      — Set to 1 for auto-reload during development.
#
# FLASK_SECRET_KEY=change-me-in-production
# FLASK_DEBUG=0
